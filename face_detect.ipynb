{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec58998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 36 frames to 'extracted_frames'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    " \n",
    "# Settings \n",
    "video_path = \"C:/Users/hp/Pictures/Camera Roll/WIN_20250811_18_15_40_Pro.mp4\"      \n",
    "output_folder = \"extracted_frames\"  \n",
    "frame_interval = 30  \n",
    " \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    " \n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    " \n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    " \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    " \n",
    "  \n",
    "    if frame_count % frame_interval == 0:\n",
    "        filename = os.path.join(output_folder, f\"frame_{saved_count:03d}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        saved_count += 1\n",
    " \n",
    "    frame_count += 1\n",
    " \n",
    "cap.release()\n",
    "print(f\"✅ Extracted {saved_count} frames to '{output_folder}'\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12944d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved average embedding for Arunima -> Arunima.npy\n",
      "✅ Saved average embedding for ayanava -> ayanava.npy\n",
      "✅ Saved average embedding for Dipasha -> Dipasha.npy\n",
      "✅ Saved average embedding for nikita -> nikita.npy\n",
      "✅ Saved average embedding for soham -> soham.npy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_path = \"extracted_frames\" \n",
    "yunet_model = \"face_detection_yunet_2023mar.onnx\"\n",
    "sface_model = \"face_recognition_sface_2021dec.onnx\"\n",
    "\n",
    "\n",
    "detector = cv2.FaceDetectorYN.create(\n",
    "    yunet_model,\n",
    "    \"\",\n",
    "    (320, 320),\n",
    "    score_threshold=0.5, \n",
    "    \n",
    ")\n",
    "\n",
    "recognizer = cv2.FaceRecognizerSF.create(\n",
    "    sface_model, \"\"\n",
    ")\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def l2_normalize(x):\n",
    "    norm = np.linalg.norm(x)\n",
    "    if norm == 0:\n",
    "        return x\n",
    "    return x / norm\n",
    "\n",
    "\n",
    "for person_name in os.listdir(dataset_path):\n",
    "    person_folder = os.path.join(dataset_path, person_name)\n",
    "    if not os.path.isdir(person_folder):\n",
    "        continue\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for img_name in os.listdir(person_folder):\n",
    "        img_path = os.path.join(person_folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Could not read {img_name}\")\n",
    "            continue\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        detector.setInputSize((w, h))\n",
    "\n",
    "        faces = detector.detect(img)\n",
    "        if faces[1] is None:\n",
    "            print(f\"No face detected in {img_name}\")\n",
    "            continue\n",
    "\n",
    "        # Take only the first detected face\n",
    "        face = faces[1][0]\n",
    "\n",
    "        aligned_face = recognizer.alignCrop(img, face)\n",
    "        face_embedding = recognizer.feature(aligned_face)\n",
    "\n",
    "        embeddings.append(face_embedding)\n",
    "\n",
    "    if embeddings:\n",
    "        embeddings = np.array(embeddings)\n",
    "        # Average embeddings and normalize\n",
    "        avg_embedding = np.mean(embeddings, axis=0)\n",
    "        avg_embedding = l2_normalize(avg_embedding)\n",
    "\n",
    "        save_path = f\"{person_name}.npy\"\n",
    "        np.save(save_path, avg_embedding)\n",
    "        print(f\"✅ Saved average embedding for {person_name} -> {save_path}\")\n",
    "    else:\n",
    "        print(f\"⚠ No embeddings saved for {person_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d52d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings for: ['Arunima', 'ayanava', 'Dipasha', 'nikita', 'soham']\n"
     ]
    }
   ],
   "source": [
    "embedding_files = [f for f in os.listdir('.') if f.endswith('.npy')]\n",
    "known_embeddings = {}\n",
    "for f in embedding_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    emb = np.load(f)\n",
    "    known_embeddings[name] = emb\n",
    "\n",
    "print(f\"Loaded embeddings for: {list(known_embeddings.keys())}\")\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    detector.setInputSize((w, h))\n",
    "\n",
    "    faces = detector.detect(frame)\n",
    "    faces_data = faces[1]\n",
    "\n",
    "    if faces_data is not None:\n",
    "        # Loop over all detected faces\n",
    "        for face in faces_data:\n",
    "            aligned_face = recognizer.alignCrop(frame, face)\n",
    "            face_embedding = recognizer.feature(aligned_face)\n",
    "            face_embedding = l2_normalize(face_embedding)\n",
    "\n",
    "            best_match = None\n",
    "            best_score = -1\n",
    "\n",
    "            for name, known_emb in known_embeddings.items():\n",
    "                score = cosine_similarity(face_embedding.flatten(), known_emb.flatten())\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = name\n",
    "\n",
    "            threshold = 0.5\n",
    "            if best_score > threshold:\n",
    "                label = f\"{best_match} ({best_score:.2f})\"\n",
    "            else:\n",
    "                label = \"Unknown\"\n",
    "\n",
    "            x, y, w_box, h_box = map(int, face[:4])\n",
    "            cv2.rectangle(frame, (x, y), (x + w_box, y + h_box), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capsitech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
